
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>10. Case Study: Debugging in Classification &#8212; MLOps</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/assignments/debugging-in-classification';</script>
    <link rel="canonical" href="https://aqwqqq.github.io/jupyter-mlops/book/assignments/debugging-in-classification.html" />
    <link rel="icon" href="../../_static/fav.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="11. Case Study: Debugging in Regression" href="debugging-in-regression.html" />
    <link rel="prev" title="9. Counterintuitive Challenges in ML Debugging" href="counterintuitive-challenges-in-ml-debugging.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="MLOps - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="MLOps - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">1. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../problem-framing.html">2. Problem framing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data-engineering.html">3. Data engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model-training-and-evaluation.html">4. Model training &amp; evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model-deployment.html">5. Model deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../markdown.html">6. Markdown Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks.html">7. Content with notebooks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="data-engineering.html">8. Data engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="counterintuitive-challenges-in-ml-debugging.html">9. Counterintuitive Challenges in ML Debugging</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">10. Case Study: Debugging in Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugging-in-regression.html">11. Case Study: Debugging in Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="random-forest-classifier.html">12. Introduction</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/Aqwqqq/jupyter-mlops.git/master?urlpath=tree/book/assignments/debugging-in-classification.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/Aqwqqq/jupyter-mlops.git/blob/master/book/assignments/debugging-in-classification.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Aqwqqq/jupyter-mlops.git" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Aqwqqq/jupyter-mlops.git/edit/main/book/assignments/debugging-in-classification.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Aqwqqq/jupyter-mlops.git/issues/new?title=Issue%20on%20page%20%2Fbook/assignments/debugging-in-classification.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/book/assignments/debugging-in-classification.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Case Study: Debugging in Classification</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-mnist-data">10.1. Load MNIST Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-data-format">10.2. Understanding the Data Format</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#do-you-have-imbalanced-classes">10.3. Do you have Imbalanced Classes?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shuffle-and-split-dataset">10.4. Shuffle and Split Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#process-data">10.5. Process Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solution">10.5.1. Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#remove-all-zero-features">10.6. Remove All-Zero Features?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#establish-baseline">10.7. Establish Baseline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-linear-model">10.8. Train a Linear Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">10.8.1. Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fixing-loss-calculation">10.9. Fixing Loss Calculation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-nonlinear-model">10.10. Train a Nonlinear Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-a-second-layer">10.11. Adding a Second Layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#check-for-training-validation-data-skew">10.12. Check for Training/Validation Data Skew</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apply-dropout-regularization">10.13. Apply Dropout Regularization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#check-accuracy-for-data-slices">10.14. Check Accuracy for Data Slices</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-for-anomalous-values">10.15. Testing for Anomalous Values</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-pass-tests-by-fixing-loss-calculation">10.16. Optional: Pass Tests by Fixing Loss Calculation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">10.17. Conclusion</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <details><summary><b>LICENSE</b></summary>
<p>Copyright 2018 Google LLC.</p>
<p>Licensed under the Apache License, Version 2.0 (the “License”);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p>
<p><a class="reference external" href="https://www.apache.org/licenses/LICENSE-2.0">https://www.apache.org/licenses/LICENSE-2.0</a></p>
<p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an “AS IS” BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>
</details><section class="tex2jax_ignore mathjax_ignore" id="case-study-debugging-in-classification">
<h1><span class="section-number">10. </span>Case Study: Debugging in Classification<a class="headerlink" href="#case-study-debugging-in-classification" title="Link to this heading">#</a></h1>
<p>This Colab quickly demonstrates a few concepts related to debugging classification models. You will explore potential problems in implementing these tasks:</p>
<ul class="simple">
<li><p>Calculating loss for classification problems.</p></li>
<li><p>Optimizing your model</p></li>
<li><p>Applying regularization.</p></li>
<li><p>Following best practices in development and debugging.</p></li>
</ul>
<p>Please <strong>make a copy</strong> of this Colab before running it. Click on <em>File</em>, and then click on <em>Save a copy in Drive</em>.</p>
<section id="load-mnist-data">
<h2><span class="section-number">10.1. </span>Load MNIST Data<a class="headerlink" href="#load-mnist-data" title="Link to this heading">#</a></h2>
<p>MNIST is a dataset of images of the numbers 0 to 9. The problem is to classify the images as numbers. Setup libraries and load the MNIST dataset. Display the first few rows to verify that the data loaded. You’ll explore the data format after the data loads.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reset environment for a new run</span>
<span class="o">%</span><span class="k">reset</span> -f

<span class="c1"># Load Libraries</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">join</span> <span class="c1"># for joining file pathnames</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">unittest</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># Set Pandas display options</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">float_format</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{:.1f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span>

<span class="c1"># Load data</span>
<span class="n">mnistDf_backup</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
  <span class="s2">&quot;https://static-1300131294.cos.ap-shanghai.myqcloud.com/data/mnist_train_small.csv&quot;</span><span class="p">,</span>
  <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">,</span>
  <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># Shuffle data</span>
<span class="n">mnistDf_backup</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Use the first 5000 examples for faster prototyping</span>
<span class="n">mnistDf</span> <span class="o">=</span> <span class="n">mnistDf_backup</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5000</span><span class="p">]</span>

<span class="n">mnistDf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="understanding-the-data-format">
<h2><span class="section-number">10.2. </span>Understanding the Data Format<a class="headerlink" href="#understanding-the-data-format" title="Link to this heading">#</a></h2>
<p>Each row represents one labeled example. Column 0 represents the label that a human rater has assigned for one handwritten digit. For example, if Column 0 contains ‘6’, then a human rater interpreted the handwritten character as the digit ‘6’.  The ten digits 0-9 are each represented, with a unique class label for each possible digit. Thus, this is a multi-class classification problem with 10 classes.</p>
<p><img alt="img" src="https://www.tensorflow.org/versions/r0.11/images/MNIST-Matrix.png" /></p>
<p>Columns 1 through 784 contain the feature values, one per pixel for the 28×28=784 pixel values. The pixel values are on a gray scale in which 0 represents white, 255 represents black, and values between 0 and 255 represent shades of gray. Most of the pixel values are 0; you may want to take a minute to confirm that they aren’t all 0.  Modify the form below and run the code to view data for a given example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">showExample</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1"># @param</span>
<span class="n">digitData</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">showExample</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">])</span>
<span class="nb">print</span> <span class="n">digitData</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="do-you-have-imbalanced-classes">
<h2><span class="section-number">10.3. </span>Do you have Imbalanced Classes?<a class="headerlink" href="#do-you-have-imbalanced-classes" title="Link to this heading">#</a></h2>
<p>As we read in the course, imbalanced classes make classification harder. Let’s look at the distribution of classes. Do you have imbalanced classes?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">hide_result</span> # hides result of cell computation
<span class="c1"># Calculate the number of classes</span>
<span class="n">numClasses</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># Plot histogram of class distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>The preceding graph shows that the 10 classes are roughly equally represented.</p>
</section>
<section id="shuffle-and-split-dataset">
<h2><span class="section-number">10.4. </span>Shuffle and Split Dataset<a class="headerlink" href="#shuffle-and-split-dataset" title="Link to this heading">#</a></h2>
<p>As part of <a class="reference external" href="https://developers.google.com/machine-learning/testing-debugging/common/data-errors">Data Debugging</a> best practices, ensure your splits are statistically equivalent by shuffling your data to remove any pre-existing order.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Shuffle data</span>
<span class="n">mnistDf</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Split dataset into data and labels</span>
<span class="n">mnistData</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mnistLabels</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="process-data">
<h2><span class="section-number">10.5. </span>Process Data<a class="headerlink" href="#process-data" title="Link to this heading">#</a></h2>
<p>Scale the data values to <code class="docutils literal notranslate"><span class="pre">[0,1]</span></code> since the values are bounded to <code class="docutils literal notranslate"><span class="pre">[0,255]</span></code> and do not contain outliers. Then check that the scaled data values are as expected by generating summary statistics using the <code class="docutils literal notranslate"><span class="pre">DataFrame.describe()</span></code> function.</p>
<p>Run the following cell to scale data and generate statistics. This cell takes a few minutes to run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">minMaxScaler</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
  <span class="nb">min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
  <span class="n">arr</span> <span class="o">=</span> <span class="p">(</span><span class="n">arr</span><span class="o">-</span><span class="nb">min</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
  <span class="k">return</span> <span class="n">arr</span>

<span class="k">for</span> <span class="n">featureIdx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
  <span class="n">mnistData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="n">featureIdx</span><span class="p">]</span> <span class="o">=</span> <span class="n">minMaxScaler</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="n">featureIdx</span><span class="p">])</span>

<span class="n">mnistData</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Oh no! Some of your features are all <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. What do you think the cause is? Hint: While NaNs have many causes, in this case, the NaN values are caused by the properties of your data. Use the next code cell to explore your data. Then check the next cell for the solution. Try to find the solution yourself. Debugging <code class="docutils literal notranslate"><span class="pre">NaN</span></code>s and exploring your data are important skills.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First reload your data</span>
<span class="n">mnistData</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Explore your data</span>
</pre></div>
</div>
</div>
</div>
<section id="solution">
<h3><span class="section-number">10.5.1. </span>Solution<a class="headerlink" href="#solution" title="Link to this heading">#</a></h3>
<p>Start exploring your data by generating a high-level summary using <code class="docutils literal notranslate"><span class="pre">Dataframe.describe()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mnistData</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Because some of the feature columns are all zeros, the scaling function divided by 0 (because <code class="docutils literal notranslate"><span class="pre">np.max</span></code> returns 0). The division by 0 resulted in NaN values. This result shows you how easily NaNs can arise in engineered data. The <code class="docutils literal notranslate"><span class="pre">describe</span></code> function will not detect every occurrence of NaN (or None). Instead,  use the command <code class="docutils literal notranslate"><span class="pre">DataFrame.isnull().any()</span></code>.</p>
<p><em>Note</em>: Given the maximum value of the feature data is 255, you could simply divide the input by 255 instead of using min-max scaling, and avoid introducing NaNs. However, this example purposely uses min-max scaling to show how NaNs can appear in engineered data.</p>
<p>Now let’s try scaling the data again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Redefine the scaling function to check for zeros</span>
<span class="k">def</span> <span class="nf">minMaxScaler</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
  <span class="k">if</span><span class="p">(</span><span class="nb">max</span><span class="o">!=</span><span class="mi">0</span><span class="p">):</span>  <span class="c1"># avoid /0</span>
    <span class="nb">min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="p">(</span><span class="n">arr</span><span class="o">-</span><span class="nb">min</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
  <span class="k">return</span> <span class="n">arr</span>

<span class="c1"># Reload data</span>
<span class="n">mnistData</span> <span class="o">=</span> <span class="n">mnistDf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Scale data</span>
<span class="k">for</span> <span class="n">featureIdx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
  <span class="n">mnistData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="n">featureIdx</span><span class="p">]</span> <span class="o">=</span> <span class="n">minMaxScaler</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="n">featureIdx</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>You should follow best practice and prevent this bug from recurring by writing a unit test to check for not having <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values in your engineered data.</p>
</section>
</section>
<section id="remove-all-zero-features">
<h2><span class="section-number">10.6. </span>Remove All-Zero Features?<a class="headerlink" href="#remove-all-zero-features" title="Link to this heading">#</a></h2>
<p>You might think that getting NaNs and discovering that some features were all-zero is good luck because those features can be discarded. However, your training data and validation data might have different all-zero features. Since you should not use validation data to make modeling decisions, you cannot remove only those features that are all-zero in both. Furthermore, data in the future might have different characteristics. There are pros and cons in either case. This Colab keeps the features since reducing the feature set is not a concern.</p>
</section>
<section id="establish-baseline">
<h2><span class="section-number">10.7. </span>Establish Baseline<a class="headerlink" href="#establish-baseline" title="Link to this heading">#</a></h2>
<p>Following development best practices, you should establish a baseline. The simplest baseline is predicting the most common class. You saw that the most common class is 1. Let’s check the accuracy when always predicting 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mnistLabels</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mf">1.0</span><span class="o">/</span><span class="n">mnistLabels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span>
</pre></div>
</div>
</div>
</div>
<p>Your baseline accuracy is about 11%. Should be easy to beat, right?</p>
</section>
<section id="train-a-linear-model">
<h2><span class="section-number">10.8. </span>Train a Linear Model<a class="headerlink" href="#train-a-linear-model" title="Link to this heading">#</a></h2>
<p>Let’s start nice and easy with a linear model. All we need is an accuracy &gt; 11%.</p>
<p>First, let’s define a function to plot our loss and accuracy curves. The function will also print the final loss and accuracy. Instead of using <code class="docutils literal notranslate"><span class="pre">verbose=1</span></code>, you can call the function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Function to:</span>
<span class="sd">   * Print final loss &amp; accuracy.</span>
<span class="sd">   * Plot loss &amp; accuracy curves.</span>

<span class="sd">  Args:</span>
<span class="sd">    trainHistory: object returned by model.fit</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># Print final loss and accuracy</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final training loss: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final validation loss: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final training accuracy: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Final validation accuracy: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

  <span class="c1"># Plot loss and accuracy curves</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
  <span class="n">axLoss</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
  <span class="n">axAcc</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
  <span class="n">axLoss</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
  <span class="n">axLoss</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
  <span class="n">axLoss</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation loss&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
  <span class="n">axLoss</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training epochs&#39;</span><span class="p">)</span>
  <span class="n">axLoss</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
  <span class="n">axAcc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">])</span>
  <span class="n">axAcc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trainHistory</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">])</span>
  <span class="n">axAcc</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation accuracy&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
  <span class="n">axAcc</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training epochs&#39;</span><span class="p">)</span>
  <span class="n">axAcc</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now train a linear model with an output layer and a hidden layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                             <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                             <span class="n">input_dim</span><span class="o">=</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span> <span class="n">mnistLabels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Wow, that accuracy is terrible! What could the cause be?</p>
<p>Hint: You followed the same procedure as for the previous regression problem. Do you need an adaptation for a classification problem? Experiment with the code above or skip to the solution below.</p>
<section id="id1">
<h3><span class="section-number">10.8.1. </span>Solution<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>In regression, the last layer uses a linear activation function. In classification, the last layer cannot use a linear transform. Instead, one option is a softmax transform. Furthermore, in regression, the loss is calculated using MSE while in classification, loss is calculated using crossentropy. Before running your model, if you wrote a test to validate the output values, your test would detect the anomalous output. You’ll look at such a test later. Move onto the next section to fix the loss calculation.</p>
</section>
</section>
<section id="fixing-loss-calculation">
<h2><span class="section-number">10.9. </span>Fixing Loss Calculation<a class="headerlink" href="#fixing-loss-calculation" title="Link to this heading">#</a></h2>
<p>Since your labels are integers instead of one-hot encodings, use <code class="docutils literal notranslate"><span class="pre">sparse_categorical_crossentropy</span></code> instead of <code class="docutils literal notranslate"><span class="pre">categorical_crossentropy</span></code> so that you avoid converting the integers to one-hot encoding.</p>
<p>Retrain the model with the new loss calculation by running the following cell. Look through the code to note the changes. What do you think of the result?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                             <span class="n">input_dim</span> <span class="o">=</span> <span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span> <span class="n">mnistLabels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Your loss curves are much better. Your accuracy has improved too. You’re on the right track.</p>
</section>
<section id="train-a-nonlinear-model">
<h2><span class="section-number">10.10. </span>Train a Nonlinear Model<a class="headerlink" href="#train-a-nonlinear-model" title="Link to this heading">#</a></h2>
<p>Switch to a nonlinear model by modifying the code below to use relu activation functions instead of linear activation functions. Run the code. What do you observe?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="c1"># use &#39;relu&#39;</span>
                             <span class="n">input_dim</span><span class="o">=</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span> <span class="n">mnistLabels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The quality of the nonlinear model is significantly better than of the linear model. Progress! Move onto the next section.</p>
</section>
<section id="adding-a-second-layer">
<h2><span class="section-number">10.11. </span>Adding a Second Layer<a class="headerlink" href="#adding-a-second-layer" title="Link to this heading">#</a></h2>
<p>Increasing the model’s capacity significantly improved your results. Perhaps you can continue this strategy by adding a second relu layer. Run the following code cell to train the model with another relu layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
                             <span class="n">input_dim</span> <span class="o">=</span> <span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span> <span class="n">mnistLabels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Guess what. Your previous model had training and validation accuracies of 100% and 95%. You can’t do much better than that! So your new accuracy is about the same. How high can you push your accuracy? With this configuration the highest training and validation accuracies appear to be 100% and 96% respectively. Since the neural net returns similar accuracy with 1 or 2 layers, let’s use the simpler model with 1 layer.</p>
<p>Does your model begin to overfit the training data if you train for long enough? (Your model starts overfitting training data at the point when your validation loss starts increasing.)</p>
</section>
<section id="check-for-training-validation-data-skew">
<h2><span class="section-number">10.12. </span>Check for Training/Validation Data Skew<a class="headerlink" href="#check-for-training-validation-data-skew" title="Link to this heading">#</a></h2>
<p>Our validation accuracy is a little worse than our training accuracy. While this result is always expected, you should check for typical errors. The commonest cause is having different distributions of data and labels in training and validation. Confirm that the distribution of classes in training and validation data is similar.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">hide_result</span> # hides result of cell computation

<span class="n">f</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)</span><span class="o">*</span><span class="mi">8</span><span class="o">/</span><span class="mi">10</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)</span><span class="o">*</span><span class="mi">8</span><span class="o">/</span><span class="mi">10</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numClasses</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="apply-dropout-regularization">
<h2><span class="section-number">10.13. </span>Apply Dropout Regularization<a class="headerlink" href="#apply-dropout-regularization" title="Link to this heading">#</a></h2>
<p>Dropout regularization is a common regularization method that removes a random selection of a fixed number of units in a network layer for a single gradient step. Typically, dropout will improve generalization at a dropout rate of between 10% and 50% of neurons.</p>
<p>Try to reduce the divergence between training and validation loss by using dropout regularization with values between 0.1 and 0.5. Dropout does not improve the results in this case. However, at a dropout of 0.5, the difference in loss decreases, though both training and validation loss decrease in absolute terms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">regularizers</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define lambda</span>
<span class="n">dropoutLambda</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1">#@param</span>
<span class="c1"># Define model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                             <span class="n">input_dim</span><span class="o">=</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                             <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropoutLambda</span><span class="p">,</span>
                               <span class="n">noise_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span>
                        <span class="n">mnistLabels</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">showClassificationResults</span><span class="p">(</span><span class="n">trainHistory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Sample results using dropout regularization after 30 epochs:</p>
<p>Lambda | Training Loss | Validation Loss
——- | ——————————————————
0.1 | 0.99 | 0.95
0.2 | 0.99 | 0.95
0.3 | 0.99 | 0.95
0.5 | 0.97 | 0.94</p>
</section>
<section id="check-accuracy-for-data-slices">
<h2><span class="section-number">10.14. </span>Check Accuracy for Data Slices<a class="headerlink" href="#check-accuracy-for-data-slices" title="Link to this heading">#</a></h2>
<p>For classification problems, you should always check the metrics by class to ensure your model predicts well across all classes. Check accuracy on the 10 classes by running the next cell by using the function <code class="docutils literal notranslate"><span class="pre">sklearn.metrics.classification_report</span></code> from the scikit-learn library. In the output, the rows with indices 0 to 9 correspond to the classes for the labels 0 to 9. The columns “Precision”, “Recall”, and “<a class="reference external" href="https://en.wikipedia.org/wiki/F1_score">F1-Score</a>” correspond to the respective classification metrics for each class. “Support” is the number of examples for the class in question. For example, for the label “4”, when predicting on 464 examples labelled “4”, the model has a precision of 0.98, a recall of 0.97, and a F1 score of 0.98.</p>
<p>The classification metrics are very uniform across all classes, which is perfect. In your classification problem, in case any metric is lower for a class, then you should investigate why the model has lower-quality predictions for that class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="n">mnistPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">mnistData</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">,</span> <span class="n">mnistPred</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="testing-for-anomalous-values">
<h2><span class="section-number">10.15. </span>Testing for Anomalous Values<a class="headerlink" href="#testing-for-anomalous-values" title="Link to this heading">#</a></h2>
<p>In the section <a class="reference external" href="https://colab.corp.google.com/google_src/cloud/karangill/mlcc/google3/engedu/ml/capitalg/colab/testing_debugging_classification.ipynb#scrollTo=B6AOgLcC5nwp">Train a Linear Model</a>, you debugged an incorrect calculation of loss. Before running your model, if you wrote a test to validate the output values, your test would detect the anomalous output. For example, you could test whether the distribution of predicted labels on the training dataset is similar to the actual distribution of training labels. A simple statistical implementation of this concept is to compare the standard deviation and mean of the predicted and actual labels.</p>
<p>First, check the standard deviation and mean of the actual labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean of actual labels: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Standard deviation of actual labels: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>Write tests to check if the mean and standard deviation of the predicted labels falls within the expected range. The expected range defined in the tests below is somewhat arbitrary. In practice, you will tune the range thresholds to accommodate natural variation in predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">mlTest</span><span class="p">(</span><span class="n">unittest</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span> 
<span class="w">  </span><span class="sd">&#39;&#39;&#39;Class to test statistics of predicted output on training data against</span>
<span class="sd">     statistics of labels to validate that model predictions are in the]</span>
<span class="sd">     expected range.</span>
<span class="sd">  &#39;&#39;&#39;</span>
     
  <span class="k">def</span> <span class="nf">testStd</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mnistData</span><span class="p">)</span>
    <span class="n">yStd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">yStdActual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)</span>
    <span class="n">deltaStd</span> <span class="o">=</span> <span class="mf">0.05</span>
    <span class="n">errorMsg</span> <span class="o">=</span> <span class="s1">&#39;Std. dev. of predicted values &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">yStd</span><span class="p">)</span> <span class="o">+</span> \
               <span class="s1">&#39; and actual values &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">yStdActual</span><span class="p">)</span> <span class="o">+</span> \
               <span class="s1">&#39; differs by &gt;&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">deltaStd</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAlmostEqual</span><span class="p">(</span><span class="n">yStd</span><span class="p">,</span> <span class="n">yStdActual</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="n">deltaStd</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="n">errorMsg</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">testMean</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mnistData</span><span class="p">)</span>
    <span class="n">yMean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">yMeanActual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mnistLabels</span><span class="p">)</span>
    <span class="n">deltaMean</span> <span class="o">=</span> <span class="mf">0.05</span>
    <span class="n">errorMsg</span> <span class="o">=</span> <span class="s1">&#39;Mean of predicted values &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">yMean</span><span class="p">)</span> <span class="o">+</span> \
               <span class="s1">&#39; and actual values &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">yMeanActual</span><span class="p">)</span> <span class="o">+</span> \
               <span class="s1">&#39; differs by &gt;&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">deltaMean</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAlmostEqual</span><span class="p">(</span><span class="n">yMean</span><span class="p">,</span> <span class="n">yMeanActual</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="n">deltaMean</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="n">errorMsg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Run the following cell to train a model with the wrong loss calculation and execute the tests. The tests should fail.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Train model and run tests</span>

<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># Define</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                             <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                             <span class="n">input_dim</span><span class="o">=</span><span class="n">mnistData</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>
<span class="c1"># Compile</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># Train</span>
<span class="n">trainHistory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">mnistData</span><span class="p">,</span> <span class="n">mnistLabels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">suite</span> <span class="o">=</span> <span class="n">unittest</span><span class="o">.</span><span class="n">TestLoader</span><span class="p">()</span><span class="o">.</span><span class="n">loadTestsFromTestCase</span><span class="p">(</span><span class="n">mlTest</span><span class="p">)</span>
<span class="n">unittest</span><span class="o">.</span><span class="n">TextTestRunner</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">suite</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Since the tests fail, check the data distribution of predicted labels for anomalies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mnistData</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">yPred</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">11</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Given equally represented classes, the predicted labels are clearly skewed. From this plot, a possible explanation is that your loss calculation does not appear to be weighting all classes equally. This anomaly is a hint that your loss calculation is incorrect.</p>
</section>
<section id="optional-pass-tests-by-fixing-loss-calculation">
<h2><span class="section-number">10.16. </span>Optional: Pass Tests by Fixing Loss Calculation<a class="headerlink" href="#optional-pass-tests-by-fixing-loss-calculation" title="Link to this heading">#</a></h2>
<p>As an optional exercise, you can attempt to pass the tests by fixing the loss calculation. You will need to:</p>
<ol class="arabic simple">
<li><p>Fix the loss calculation by setting the output layer’s activation to <code class="docutils literal notranslate"><span class="pre">softmax</span></code>.</p></li>
<li><p>Set the model’s loss to <code class="docutils literal notranslate"><span class="pre">sparse_categorical_crossentropy</span></code>.</p></li>
<li><p>Set the number of units in the output layer to 10 corresponding to the 10 classes.</p></li>
<li><p>Adapt the tests to the modified output layer.</p></li>
</ol>
</section>
<section id="conclusion">
<h2><span class="section-number">10.17. </span>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>The Colab demonstrated the following principles:</p>
<ul class="simple">
<li><p>Calculate loss correctly for your problem.</p></li>
<li><p>Verify and unit test your engineered data.</p></li>
<li><p>Find the right model capacity through experimentation.</p></li>
<li><p>Find the best regularization through experimentation.</p></li>
<li><p>Check quality on data slices.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book/assignments"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="counterintuitive-challenges-in-ml-debugging.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">9. </span>Counterintuitive Challenges in ML Debugging</p>
      </div>
    </a>
    <a class="right-next"
       href="debugging-in-regression.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11. </span>Case Study: Debugging in Regression</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-mnist-data">10.1. Load MNIST Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-data-format">10.2. Understanding the Data Format</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#do-you-have-imbalanced-classes">10.3. Do you have Imbalanced Classes?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shuffle-and-split-dataset">10.4. Shuffle and Split Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#process-data">10.5. Process Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solution">10.5.1. Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#remove-all-zero-features">10.6. Remove All-Zero Features?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#establish-baseline">10.7. Establish Baseline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-linear-model">10.8. Train a Linear Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">10.8.1. Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fixing-loss-calculation">10.9. Fixing Loss Calculation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-nonlinear-model">10.10. Train a Nonlinear Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-a-second-layer">10.11. Adding a Second Layer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#check-for-training-validation-data-skew">10.12. Check for Training/Validation Data Skew</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apply-dropout-regularization">10.13. Apply Dropout Regularization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#check-accuracy-for-data-slices">10.14. Check Accuracy for Data Slices</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-for-anomalous-values">10.15. Testing for Anomalous Values</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-pass-tests-by-fixing-loss-calculation">10.16. Optional: Pass Tests by Fixing Loss Calculation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">10.17. Conclusion</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Xu Mingrui
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>